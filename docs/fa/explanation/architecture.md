# نمای کلی معماری

این سند معماری KTTC، تصمیمات طراحی و نحوه همکاری اجزا را توضیح می‌دهد.

## معماری سیستم

```
┌─────────────────────────────────────────────────────────────┐
│                         CLI Layer                           │
│  (kttc check, batch, translate, compare, benchmark)         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   Orchestration Layer                       │
│  • AgentOrchestrator                                        │
│  • DynamicAgentSelector (budget-aware)                      │
│  • WeightedConsensus                                        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                    Multi-Agent QA System                    │
│  ┌───────────┐  ┌────────────┐  ┌─────────────┐            │
│  │ Accuracy  │  │  Fluency   │  │Terminology  │            │
│  │  Agent    │  │   Agent    │  │   Agent     │            │
│  └───────────┘  └────────────┘  └─────────────┘            │
│  ┌───────────┐  ┌────────────┐                             │
│  │Hallucin-  │  │  Context   │                             │
│  │ation Agent│  │   Agent    │                             │
│  └───────────┘  └────────────┘                             │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│               Language-Specific Helpers                     │
│  • EnglishLanguageHelper (LanguageTool integration)         │
│  • ChineseLanguageHelper (HanLP integration)                │
│  • RussianLanguageHelper (MAWO NLP integration)             │
│    → Anti-hallucination verification for LLM outputs        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                     LLM Layer                               │
│  • ComplexityRouter (smart model selection)                 │
│  • ModelSelector (language pair optimization)               │
│  • Providers: OpenAI, Anthropic, GigaChat, Yandex          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                 Supporting Systems                          │
│  • TranslationMemory (semantic search, MQM tracking)        │
│  • TerminologyBase (glossary management)                    │
│  • AutoCorrector (LLM-powered error fixing)                 │
│  • IterativeRefinement (TEaR loop)                          │
└─────────────────────────────────────────────────────────────┘
```

## اجزای اصلی

### 1. سیستم QA چند عاملی

KTTC از عامل‌های تخصصی برای ارزیابی ابعاد مختلف کیفیت بر اساس چارچوب MQM (Multidimensional Quality Metrics) استفاده می‌کند.

**عامل‌های پایه (همیشه فعال):**

- **AccuracyAgent** - صحت معنایی، حفظ معنی، تشخیص ترجمه نادرست
- **FluencyAgent** - دستور زبان، طبیعی بودن، خوانایی (کلاس پایه)
- **TerminologyAgent** - ثبات اصطلاحات خاص حوزه، اعتبارسنجی واژه‌نامه
- **HallucinationAgent** - تشخیص محتوای ساختگی، حفظ موجودیت
- **ContextAgent** - ثبات سطح سند، اعتبارسنجی ارجاع متقابل

**عامل‌های روانی خاص زبان:**

به طور خودکار بر اساس زبان مقصد انتخاب می‌شوند:

- **EnglishFluencyAgent** (`target_lang == "en"`)
  - یکپارچگی LanguageTool: 5000+ قاعده دستوری
  - توافق فاعل و فعل، حروف تعریف، حروف اضافه
  - spaCy برای شناسایی موجودیت نام‌گذاری شده

- **ChineseFluencyAgent** (`target_lang == "zh"`)
  - یکپارچگی HanLP: اعتبارسنجی کلمات اندازه‌گیری (量词)
  - بررسی ذرات جنبه (了/过)
  - برچسب‌گذاری POS با دقت بالا (~95%)

- **RussianFluencyAgent** (`target_lang == "ru"`)
  - پشته NLP MAWO: تحلیل صرفی
  - توافق حالت (6 حالت)، اعتبارسنجی جنبه فعل
  - استفاده از ذره (же، ли، бы)، ثبات رجیستر (ты/вы)

### 2. رویکرد ترکیبی NLP + LLM

**چرا ترکیبی؟**

رویکردهای خالص LLM در وظایف QA از توهم رنج می‌برند. KTTC ترکیب می‌کند:

1. **NLP قطعی** - بررسی‌های مبتنی بر قاعده (بدون توهم)
2. **هوش LLM** - درک معنایی، آگاهی از زمینه
3. **تأیید ضد توهم** - NLP خروجی‌های LLM را تأیید می‌کند

**جریان:**

```
متن → تحلیل NLP (قطعی) → تحلیل LLM (معنایی)
                                            ↓
                      ← تأیید ضد توهم ←
                                            ↓
                                      خطاهای تأیید شده
```

**مثال (روسی):**

```python
# NLP عدم تطابق حالت را تشخیص می‌دهد
nlp_error = "Adjective 'красный' should agree with noun 'дом' in case"

# LLM مشکل معنایی را تشخیص می‌دهد
llm_error = "Unnatural word order in Russian"

# NLP تأیید می‌کند که LLM توهم نداشته
# (بررسی می‌کند که خطای ادعا شده LLM واقعاً در متن وجود دارد)

# بازگشت: خطاهای NLP + فقط خطاهای تأیید شده LLM
```

### 3. سیستم مسیریابی هوشمند

**ComplexityRouter** پیچیدگی متن را تحلیل می‌کند و به مدل‌های مناسب مسیریابی می‌کند:

**عوامل پیچیدگی:**

- طول و ساختار جمله
- فرکانس کلمات نادر
- پیچیدگی نحوی (عمق وابستگی)
- تراکم اصطلاحات خاص حوزه

**تصمیم مسیریابی:**

```
امتیاز پیچیدگی (0.0-1.0):
├─ 0.0-0.3: ساده → GPT-4o-mini (ارزان، سریع)
├─ 0.3-0.7: متوسط → Claude 3.5 Sonnet (متعادل)
└─ 0.7-1.0: پیچیده → GPT-4.5/o1-preview (بهترین کیفیت)
```

**مزایا:**

- کاهش 60% هزینه در متون ساده
- همان کیفیت با استفاده همیشگی از مدل‌های ممتاز
- خودکار، بدون پیکربندی دستی

### 4. امتیازدهی MQM

KTTC چارچوب MQM مورد استفاده در معیارهای WMT را پیاده‌سازی می‌کند.

**وزن شدت خطا:**

- **خنثی:** 0 امتیاز (بدون جریمه)
- **جزئی:** 1 امتیاز (غلط تایپی، ترجیحات سبک)
- **عمده:** 5 امتیاز (خطاهای دستوری، ترجمه نادرست)
- **بحرانی:** 10 امتیاز (حذف، تغییر معنی)

**فرمول:**

```
امتیاز MQM = 100 - (total_penalty / word_count * 1000)
```

**مثال:**

```
متن: 50 کلمه
خطاها: 1 جزئی، 2 عمده
جریمه: 1*1 + 2*5 = 11
امتیاز MQM: 100 - (11 / 50 * 1000) = 100 - 220 = 78.0
```

**سطوح کیفیت:**

- **95-100:** عالی (آماده تولید)
- **90-94:** خوب (نیاز به اصلاحات جزئی)
- **80-89:** قابل قبول (نیاز به بازنگری)
- **<80:** ضعیف (نیاز به بازکار قابل توجه)

### 5. حافظه ترجمه

**جستجوی معنایی با ردیابی MQM:**

```python
# ذخیره ترجمه با امتیاز کیفیت
await tm.add_translation(
    source="API request",
    translation="Запрос API",
    mqm_score=98.5,
    domain="technical"
)

# یافتن ترجمه‌های مشابه (sentence-transformers)
results = await tm.search_similar(
    source="API call",
    threshold=0.80  # Cosine similarity
)
# بازگشت: "Запрос API" (similarity: 0.92, MQM: 98.5)
```

**مزایا:**

- استفاده مجدد از ترجمه‌های با کیفیت بالا
- اصطلاحات ثابت در پروژه‌ها
- سازماندهی خاص حوزه

### 6. سیستم اصلاح خودکار

**AutoCorrector** از LLM برای اصلاح طبیعی خطاهای شناسایی شده استفاده می‌کند:

**سطوح:**

- **سبک:** فقط خطاهای بحرانی و عمده را اصلاح کنید
- **کامل:** تمام خطاهای شناسایی شده را اصلاح کنید

**فرآیند:**

```
1. عامل‌ها خطاها را شناسایی می‌کنند
2. AutoCorrector دستور اصلاح تولید می‌کند
3. LLM در زمینه اصلاح می‌کند
4. با عامل‌ها دوباره ارزیابی کنید
5. تا رسیدن به آستانه تکرار کنید (حداکثر تکرار)
```

**نتایج:**

- 40% سریعتر از ویرایش دستی پس از تولید
- کاهش 60% هزینه در مقایسه با ویرایش انسانی
- حفظ زمینه و طبیعی بودن

### 7. حلقه TEaR (Translate-Estimate-Refine)

**IterativeRefinement** روش TEaR را پیاده‌سازی می‌کند:

```
1. TRANSLATE: تولید ترجمه اولیه (LLM)
2. ESTIMATE: ارزیابی کیفیت (Multi-agent QA)
3. REFINE: اصلاح خطاها و بهبود (AutoCorrector)
4. تکرار 2-3 تا همگرایی یا حداکثر تکرار
```

**معیارهای همگرایی:**

- امتیاز MQM ≥ آستانه (مثلاً 95.0)
- بهبود < حداقل (مثلاً 1.0 امتیاز)
- حداکثر تکرار رسیده (مثلاً 3)

## تصمیمات طراحی

### چرا چند عاملی به جای LLM تکی؟

**رویکرد LLM تکی:**

- مستعد توهم در وظایف QA
- ممکن است خطاهای خاص زبان را از دست بدهد
- دسته‌بندی ناهماهنگ خطاها

**رویکرد چند عاملی:**

- هر عامل در یک بعد تخصصی
- اجرای موازی (سریعتر)
- ترکیبی NLP+LLM توهم را کاهش می‌دهد
- دسته‌بندی خطای سازگار با MQM

**پشتوانه تحقیقاتی:** یافته‌های WMT 2025 نشان می‌دهند سیستم‌های چند عاملی 15-20% بهتر از QA تک مدلی در دقت عمل می‌کنند.

### چرا عامل‌های خاص زبان؟

**مشکل:** عامل‌های روانی عمومی خطاهای خاص زبان را از دست می‌دهند:

- انگلیسی: حروف تعریف (a/an/the)، توافق فاعل و فعل
- چینی: کلمات اندازه‌گیری (量词)، ذرات جنبه (了/过)
- روسی: توافق حالت (6 حالت)، جنبه فعل

**راه‌حل:** عامل‌های تخصصی با دانش گویشور بومی رمزگذاری شده از طریق کتابخانه‌های NLP.

**فعال‌سازی:** خودکار انتخاب شده بر اساس `target_lang`:

```python
if target_lang == "en":
    fluency_agent = EnglishFluencyAgent()
elif target_lang == "zh":
    fluency_agent = ChineseFluencyAgent()
elif target_lang == "ru":
    fluency_agent = RussianFluencyAgent()
else:
    fluency_agent = FluencyAgent()  # Generic
```

### چرا ترکیبی NLP + LLM؟

**مشکلات خالص LLM:**

- توهم: ادعای خطاهایی که وجود ندارند
- ناهماهنگی: خطاهای مختلف در اجراهای مجدد
- هزینه: گران برای بررسی‌های ساده

**مشکلات خالص NLP:**

- درک محدود معنایی
- نمی‌تواند مسائل زمینه‌ای را تشخیص دهد
- نیاز به مهندسی گسترده قاعده

**مزایای ترکیبی:**

- NLP بررسی‌های قطعی ارائه می‌دهد (بدون توهم)
- LLM درک معنایی ارائه می‌دهد
- NLP خروجی‌های LLM را تأیید می‌کند (ضد توهم)
- مقرون به صرفه: از NLP برای بررسی‌های ساده، LLM برای پیچیده استفاده کنید

### چرا مسیریابی هوشمند؟

**مشکل:** استفاده از GPT-4.5 برای "Hello, world!" اتلاف است.

**راه‌حل:** مسیریابی بر اساس پیچیدگی:

- متون ساده → مدل‌های ارزان‌تر (GPT-4o-mini)
- متون پیچیده → مدل‌های ممتاز (GPT-4.5، o1-preview)

**تأثیر:**

- کاهش 60% هزینه در عمل
- بدون کاهش کیفیت
- خودکار، شفاف برای کاربران

## ویژگی‌های عملکرد

### تأخیر

**ترجمه تکی (100 کلمه):**

- تحلیل NLP: ~0.1s
- ارزیابی عامل (5 عامل، موازی): ~2-5s
- کل: ~2-6s

**پردازش دسته‌ای (1000 ترجمه):**

- ترتیبی: ~50-100 دقیقه
- موازی (4 کارگر): ~12-25 دقیقه
- موازی (8 کارگر): ~6-12 دقیقه

### هزینه‌ها

**به ازای 1000 کلمه (GPT-4o-mini + مسیریابی هوشمند):**

- بررسی کیفیت: $0.01-0.05
- ترجمه + QA: $0.05-0.15
- با اصلاح خودکار: $0.10-0.25

**مقایسه با بررسی دستی:**

- انسان: $100-500 به ازای 1000 کلمه
- KTTC: $0.01-0.25 به ازای 1000 کلمه
- صرفه‌جویی: 90-99%

### دقت

**تشخیص خطا (در مقابل معیارهای WMT):**

- دقت: 85-92% (مثبت کاذب کم)
- فراخوان: 78-88% (اکثر خطاهای واقعی را پیدا می‌کند)
- امتیاز F1: 81-90%

**همبستگی امتیاز MQM:**

- در مقابل MQM انسانی: r = 0.82-0.89 (همبستگی قوی)

## مقیاس‌پذیری

**مقیاس‌بندی افقی:**

- طراحی بدون وضعیت (هر بررسی مستقل)
- پردازش دسته‌ای موازی
- بدون وضعیت مشترک بین کارگران

**مقیاس‌بندی عمودی:**

- Async/await در سراسر
- فراخوانی‌های همزمان API LLM
- بهینه حافظه (جریان برای فایل‌های بزرگ)

**استقرار تولید:**

```
Load Balancer
    ↓
┌─────────┬─────────┬─────────┐
│ Worker  │ Worker  │ Worker  │
│   1     │   2     │   3     │
└─────────┴─────────┴─────────┘
    ↓         ↓         ↓
┌─────────────────────────────┐
│   Shared Translation Memory │
│   Shared Terminology Base   │
└─────────────────────────────┘
```

## همچنین ببینید

- [سیستم عامل](agent-system.md) - بررسی عمیق عامل‌ها
- [چارچوب MQM](mqm-scoring.md) - جزئیات امتیازدهی
- [معماری CLI](../guides/cli-usage.md) - طراحی CLI
- [مرجع API](../reference/api-reference.md) - Python API
