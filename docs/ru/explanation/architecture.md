# Обзор архитектуры

Этот документ объясняет архитектуру KTTC, проектные решения и то, как компоненты работают вместе.

## Архитектура системы

```
┌─────────────────────────────────────────────────────────────┐
│                         CLI Layer                           │
│  (kttc check, batch, translate, compare, benchmark)         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   Orchestration Layer                       │
│  • AgentOrchestrator                                        │
│  • DynamicAgentSelector (budget-aware)                      │
│  • WeightedConsensus                                        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                    Multi-Agent QA System                    │
│  ┌───────────┐  ┌────────────┐  ┌─────────────┐            │
│  │ Accuracy  │  │  Fluency   │  │Terminology  │            │
│  │  Agent    │  │   Agent    │  │   Agent     │            │
│  └───────────┘  └────────────┘  └─────────────┘            │
│  ┌───────────┐  ┌────────────┐                             │
│  │Hallucin-  │  │  Context   │                             │
│  │ation Agent│  │   Agent    │                             │
│  └───────────┘  └────────────┘                             │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│               Language-Specific Helpers                     │
│  • EnglishLanguageHelper (LanguageTool integration)         │
│  • ChineseLanguageHelper (HanLP integration)                │
│  • RussianLanguageHelper (MAWO NLP integration)             │
│    → Anti-hallucination verification for LLM outputs        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                     LLM Layer                               │
│  • ComplexityRouter (smart model selection)                 │
│  • ModelSelector (language pair optimization)               │
│  • Providers: OpenAI, Anthropic, GigaChat, Yandex          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                 Supporting Systems                          │
│  • TranslationMemory (semantic search, MQM tracking)        │
│  • TerminologyBase (glossary management)                    │
│  • AutoCorrector (LLM-powered error fixing)                 │
│  • IterativeRefinement (TEaR loop)                          │
└─────────────────────────────────────────────────────────────┘
```

## Основные компоненты

### 1. Мульти-агентная система QA

KTTC использует специализированных агентов для оценки различных измерений качества в соответствии с фреймворком MQM (Многомерные метрики качества).

**Базовые агенты (всегда активны):**

- **AccuracyAgent** - Семантическая корректность, сохранение смысла, обнаружение неправильных переводов
- **FluencyAgent** - Грамматика, естественность, читаемость (базовый класс)
- **TerminologyAgent** - Согласованность доменной терминологии, валидация глоссария
- **HallucinationAgent** - Обнаруживает сфабрикованное содержание, сохранение сущностей
- **ContextAgent** - Согласованность на уровне документа, валидация перекрестных ссылок

**Языково-специфичные агенты беглости речи:**

Автоматически выбираются на основе целевого языка:

- **EnglishFluencyAgent** (`target_lang == "en"`)
  - Интеграция с LanguageTool: более 5000 грамматических правил
  - Согласование подлежащего и сказуемого, артикли, предлоги
  - spaCy для распознавания именованных сущностей

- **ChineseFluencyAgent** (`target_lang == "zh"`)
  - Интеграция с HanLP: валидация счетных слов (量词)
  - Проверка видовых частиц (了/过)
  - Высокоточная POS-разметка (~95%)

- **RussianFluencyAgent** (`target_lang == "ru"`)
  - Стек MAWO NLP: морфологический анализ
  - Согласование падежей (6 падежей), валидация видов глагола
  - Использование частиц (же, ли, бы), согласованность регистра (ты/вы)

### 2. Гибридный подход NLP + LLM

**Почему гибридный?**

Чисто LLM-подходы страдают от галлюцинаций в задачах QA. KTTC сочетает:

1. **Детерминированный NLP** - Проверки на основе правил (без галлюцинаций)
2. **Интеллект LLM** - Семантическое понимание, осведомленность о контексте
3. **Верификация против галлюцинаций** - NLP проверяет выходы LLM

**Поток:**

```
Текст → NLP анализ (детерминированный) → LLM анализ (семантический)
                                            ↓
                      ← Верификация против галлюцинаций ←
                                            ↓
                                    Верифицированные ошибки
```

**Пример (русский):**

```python
# NLP обнаруживает несоответствие падежей
nlp_error = "Прилагательное 'красный' должно согласоваться с существительным 'дом' в падеже"

# LLM обнаруживает семантическую проблему
llm_error = "Неестественный порядок слов в русском языке"

# NLP проверяет, что LLM не галлюцинирует
# (проверяет, действительно ли заявленная LLM ошибка существует в тексте)

# Возвращает: только NLP ошибки + Верифицированные LLM ошибки
```

### 3. Система умной маршрутизации

**ComplexityRouter** анализирует сложность текста и направляет к подходящим моделям:

**Факторы сложности:**

- Длина и структура предложения
- Частота редких слов
- Синтаксическая сложность (глубина зависимостей)
- Плотность доменной терминологии

**Решение о маршрутизации:**

```
Оценка сложности (0.0-1.0):
├─ 0.0-0.3: Простой → GPT-4o-mini (дешево, быстро)
├─ 0.3-0.7: Средний → Claude 3.5 Sonnet (сбалансированный)
└─ 0.7-1.0: Сложный → GPT-4.5/o1-preview (лучшее качество)
```

**Преимущества:**

- 60% снижение стоимости на простых текстах
- То же качество, что и при постоянном использовании премиум-моделей
- Автоматическое, без ручной настройки

### 4. Оценка MQM

KTTC реализует фреймворк MQM, используемый в бенчмарках WMT.

**Веса серьезности ошибок:**

- **Нейтральная:** 0 баллов (без штрафа)
- **Незначительная:** 1 балл (опечатки, стилистические предпочтения)
- **Значительная:** 5 баллов (грамматические ошибки, неправильные переводы)
- **Критическая:** 10 баллов (пропуски, изменения смысла)

**Формула:**

```
Оценка MQM = 100 - (общий_штраф / количество_слов * 1000)
```

**Пример:**

```
Текст: 50 слов
Ошибки: 1 незначительная, 2 значительные
Штраф: 1*1 + 2*5 = 11
Оценка MQM: 100 - (11 / 50 * 1000) = 100 - 220 = 78.0
```

**Уровни качества:**

- **95-100:** Отличное (готово к продакшену)
- **90-94:** Хорошее (нужны незначительные исправления)
- **80-89:** Приемлемое (нужна ревизия)
- **<80:** Плохое (требуется значительная переработка)

### 5. Память переводов

**Семантический поиск с отслеживанием MQM:**

```python
# Сохранить перевод с оценкой качества
await tm.add_translation(
    source="API request",
    translation="Запрос API",
    mqm_score=98.5,
    domain="technical"
)

# Найти похожие переводы (sentence-transformers)
results = await tm.search_similar(
    source="API call",
    threshold=0.80  # Косинусное сходство
)
# Возвращает: "Запрос API" (сходство: 0.92, MQM: 98.5)
```

**Преимущества:**

- Повторное использование высококачественных переводов
- Согласованная терминология в проектах
- Доменная организация

### 6. Система автокоррекции

**AutoCorrector** использует LLM для естественного исправления обнаруженных ошибок:

**Уровни:**

- **Легкий:** Исправлять только критические и значительные ошибки
- **Полный:** Исправлять все обнаруженные ошибки

**Процесс:**

```
1. Агенты обнаруживают ошибки
2. AutoCorrector генерирует промпт для исправления
3. LLM исправляет в контексте
4. Повторная оценка агентами
5. Повторить до достижения порога (макс. итераций)
```

**Результаты:**

- На 40% быстрее ручного постредактирования
- 60% снижение стоимости по сравнению с человеческим редактированием
- Сохраняет контекст и естественность

### 7. Цикл TEaR (Translate-Estimate-Refine)

**IterativeRefinement** реализует методологию TEaR:

```
1. ПЕРЕВОДИТЬ: Генерировать начальный перевод (LLM)
2. ОЦЕНИВАТЬ: Оценить качество (Мульти-агентное QA)
3. УТОЧНЯТЬ: Исправить ошибки и улучшить (AutoCorrector)
4. Повторить 2-3 до сходимости или макс. итераций
```

**Критерии сходимости:**

- Оценка MQM ≥ порога (например, 95.0)
- Улучшение < минимума (например, 1.0 балл)
- Достигнуто максимальное количество итераций (например, 3)

## Проектные решения

### Почему мульти-агент вместо одной LLM?

**Подход с одной LLM:**

- Склонен к галлюцинациям в задачах QA
- Может пропускать языково-специфичные ошибки
- Непоследовательная категоризация ошибок

**Мульти-агентный подход:**

- Каждый агент специализируется на одном измерении
- Параллельное выполнение (быстрее)
- Гибрид NLP+LLM уменьшает галлюцинации
- MQM-совместимая категоризация ошибок

**Научное обоснование:** Результаты WMT 2025 показывают, что мульти-агентные системы превосходят одномодельное QA на 15-20% по точности.

### Почему языково-специфичные агенты?

**Проблема:** Общие агенты беглости пропускают языково-специфичные ошибки:

- Английский: Артикли (a/an/the), согласование подлежащего и сказуемого
- Китайский: Счетные слова (量词), видовые частицы (了/过)
- Русский: Согласование падежей (6 падежей), вид глагола

**Решение:** Специализированные агенты с знанием носителя языка, закодированным через NLP-библиотеки.

**Активация:** Автовыбор на основе `target_lang`:

```python
if target_lang == "en":
    fluency_agent = EnglishFluencyAgent()
elif target_lang == "zh":
    fluency_agent = ChineseFluencyAgent()
elif target_lang == "ru":
    fluency_agent = RussianFluencyAgent()
else:
    fluency_agent = FluencyAgent()  # Общий
```

### Почему гибрид NLP + LLM?

**Проблемы чисто LLM:**

- Галлюцинации: Заявляет ошибки, которых не существует
- Непоследовательность: Разные ошибки при повторных запусках
- Стоимость: Дорого для простых проверок

**Проблемы чисто NLP:**

- Ограниченное семантическое понимание
- Не может обнаружить контекстные проблемы
- Требует обширной инженерии правил

**Преимущества гибрида:**

- NLP обеспечивает детерминированные проверки (без галлюцинаций)
- LLM обеспечивает семантическое понимание
- NLP проверяет выходы LLM (против галлюцинаций)
- Экономически эффективно: Использовать NLP для простых проверок, LLM для сложных

### Почему умная маршрутизация?

**Проблема:** Использование GPT-4.5 для "Hello, world!" расточительно.

**Решение:** Маршрутизация на основе сложности:

- Простые тексты → Более дешевые модели (GPT-4o-mini)
- Сложные тексты → Премиум модели (GPT-4.5, o1-preview)

**Влияние:**

- 60% снижение стоимости на практике
- Без деградации качества
- Автоматическое, прозрачное для пользователей

## Характеристики производительности

### Задержка

**Один перевод (100 слов):**

- NLP анализ: ~0.1с
- Оценка агентами (5 агентов, параллельно): ~2-5с
- Всего: ~2-6с

**Пакетная обработка (1000 переводов):**

- Последовательно: ~50-100 минут
- Параллельно (4 воркера): ~12-25 минут
- Параллельно (8 воркеров): ~6-12 минут

### Стоимость

**На 1000 слов (GPT-4o-mini + умная маршрутизация):**

- Проверка качества: $0.01-0.05
- Перевод + QA: $0.05-0.15
- С автокоррекцией: $0.10-0.25

**Сравнение с ручной проверкой:**

- Человек: $100-500 на 1000 слов
- KTTC: $0.01-0.25 на 1000 слов
- Экономия: 90-99%

### Точность

**Обнаружение ошибок (в сравнении с бенчмарками WMT):**

- Точность: 85-92% (мало ложных срабатываний)
- Полнота: 78-88% (находит большинство реальных ошибок)
- F1 Score: 81-90%

**Корреляция оценки MQM:**

- в сравнении с человеческой MQM: r = 0.82-0.89 (сильная корреляция)

## Масштабируемость

**Горизонтальное масштабирование:**

- Бесстатусный дизайн (каждая проверка независима)
- Параллельная пакетная обработка
- Нет общего состояния между воркерами

**Вертикальное масштабирование:**

- Async/await повсюду
- Конкурентные вызовы API LLM
- Эффективная память (стриминг для больших файлов)

**Продакшен развертывание:**

```
Load Balancer
    ↓
┌─────────┬─────────┬─────────┐
│ Worker  │ Worker  │ Worker  │
│   1     │   2     │   3     │
└─────────┴─────────┴─────────┘
    ↓         ↓         ↓
┌─────────────────────────────┐
│   Shared Translation Memory │
│   Shared Terminology Base   │
└─────────────────────────────┘
```

## См. также

- [Система агентов](agent-system.md) - Подробное изучение агентов
- [Фреймворк MQM](mqm-scoring.md) - Детали оценки
- [Архитектура CLI](../guides/cli-usage.md) - Дизайн CLI
- [Справочник API](../reference/api-reference.md) - Python API