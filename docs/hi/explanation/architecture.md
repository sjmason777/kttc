# आर्किटेक्चर अवलोकन

यह दस्तावेज़ KTTC की आर्किटेक्चर, डिज़ाइन निर्णयों और घटकों के एक साथ काम करने के तरीके की व्याख्या करता है।

## सिस्टम आर्किटेक्चर

```
┌─────────────────────────────────────────────────────────────┐
│                         CLI Layer                           │
│  (kttc check, batch, translate, compare, benchmark)         │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   Orchestration Layer                       │
│  • AgentOrchestrator                                        │
│  • DynamicAgentSelector (budget-aware)                      │
│  • WeightedConsensus                                        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                    Multi-Agent QA System                    │
│  ┌───────────┐  ┌────────────┐  ┌─────────────┐            │
│  │ Accuracy  │  │  Fluency   │  │Terminology  │            │
│  │  Agent    │  │   Agent    │  │   Agent     │            │
│  └───────────┘  └────────────┘  └─────────────┘            │
│  ┌───────────┐  ┌────────────┐                             │
│  │Hallucin-  │  │  Context   │                             │
│  │ation Agent│  │   Agent    │                             │
│  └───────────┘  └────────────┘                             │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│               Language-Specific Helpers                     │
│  • EnglishLanguageHelper (LanguageTool integration)         │
│  • ChineseLanguageHelper (HanLP integration)                │
│  • RussianLanguageHelper (MAWO NLP integration)             │
│    → Anti-hallucination verification for LLM outputs        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                     LLM Layer                               │
│  • ComplexityRouter (smart model selection)                 │
│  • ModelSelector (language pair optimization)               │
│  • Providers: OpenAI, Anthropic, GigaChat, Yandex          │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                 Supporting Systems                          │
│  • TranslationMemory (semantic search, MQM tracking)        │
│  • TerminologyBase (glossary management)                    │
│  • AutoCorrector (LLM-powered error fixing)                 │
│  • IterativeRefinement (TEaR loop)                          │
└─────────────────────────────────────────────────────────────┘
```

## मुख्य घटक

### 1. मल्टी-एजेंट QA सिस्टम

KTTC MQM (Multidimensional Quality Metrics) फ्रेमवर्क के बाद विभिन्न गुणवत्ता आयामों का मूल्यांकन करने के लिए विशेष एजेंटों का उपयोग करता है।

**बेस एजेंट (हमेशा सक्रिय):**

- **AccuracyAgent** - सिमेंटिक शुद्धता, अर्थ संरक्षण, गलत अनुवाद पहचान
- **FluencyAgent** - व्याकरण, प्रकृतिता, पठनीयता (बेस क्लास)
- **TerminologyAgent** - डोमेन-विशिष्ट शब्द स्थिरता, शब्दकोश सत्यापन
- **HallucinationAgent** - गढ़ी गई सामग्री का पता लगाता है, इकाई संरक्षण
- **ContextAgent** - दस्तावेज़-स्तर की स्थिरता, क्रॉस-रेफरेंस सत्यापन

**भाषा-विशिष्ट फ्लूएन्सी एजेंट:**

लक्ष्य भाषा के आधार पर स्वचालित रूप से चयनित:

- **EnglishFluencyAgent** (`target_lang == "en"`)
  - LanguageTool एकीकरण: 5,000+ व्याकरण नियम
  - विषय-क्रिया समझौता, आर्टिकल्स, प्रीपोजीशन्स
  - नामित इकाई पहचान के लिए spaCy

- **ChineseFluencyAgent** (`target_lang == "zh"`)
  - HanLP एकीकरण: माप शब्द सत्यापन (量词)
  - पहलू कण जाँच (了/过)
  - उच्च-सटीक POS टैगिंग (~95%)

- **RussianFluencyAgent** (`target_lang == "ru"`)
  - MAWO NLP स्टैक: रूपात्मक विश्लेषण
  - केस समझौता (6 केस), क्रिया पहलू सत्यापन
  - कण उपयोग (же, ли, бы), रजिस्टर स्थिरता (ты/вы)

### 2. हाइब्रिड NLP + LLM दृष्टिकोण

**हाइब्रिड क्यों?**

शुद्ध LLM दृष्टिकोण QA कार्यों में हॅल्युसिनेशन से पीड़ित होते हैं। KTTC संयोजन करता है:

1. **निर्धारक NLP** - नियम-आधारित जाँच (कोई हॅल्युसिनेशन नहीं)
2. **LLM इंटेलिजेंस** - सिमेंटिक समझ, संदर्भ जागरूकता
3. **एंटी-हॅल्युसिनेशन सत्यापन** - NLP LLM आउटपुट सत्यापित करता है

**प्रवाह:**

```
पाठ → NLP विश्लेषण (निर्धारक) → LLM विश्लेषण (सिमेंटिक)
                                            ↓
                      ← एंटी-हॅल्युसिनेशन सत्यापन ←
                                            ↓
                                      सत्यापित त्रुटियां
```

**उदाहरण (रूसी):**

```python
# NLP केस बेमेल का पता लगाता है
nlp_error = "Adjective 'красный' should agree with noun 'дом' in case"

# LLM सिमेंटिक मुद्दा पता लगाता है
llm_error = "Unnatural word order in Russian"

# NLP सत्यापित करता है कि LLM ने हॅल्युसिनेट नहीं किया
# (जाँचता है कि LLM की दावा की गई त्रुटि वास्तव में पाठ में मौजूद है)

# रिटर्न: NLP त्रुटियां + केवल सत्यापित LLM त्रुटियां
```

### 3. स्मार्ट रूटिंग सिस्टम

**ComplexityRouter** पाठ जटिलता का विश्लेषण करता है और उपयुक्त मॉडल को रूट करता है:

**जटिलता कारक:**

- वाक्य लंबाई और संरचना
- दुर्लभ शब्द आवृत्ति
- वाक्यविन्यास जटिलता (निर्भरता गहराई)
- डोमेन-विशिष्ट शब्दावली घनत्व

**रूटिंग निर्णय:**

```
जटिलता स्कोर (0.0-1.0):
├─ 0.0-0.3: सरल → GPT-4o-mini (सस्ता, तेज़)
├─ 0.3-0.7: मध्यम → Claude 3.5 Sonnet (संतुलित)
└─ 0.7-1.0: जटिल → GPT-4.5/o1-preview (सर्वोत्तम गुणवत्ता)
```

**लाभ:**

- सरल पाठों पर 60% लागत में कमी
- प्रीमियम मॉडल हमेशा उपयोग करने के समान गुणवत्ता
- स्वचालित, कोई मैन्युअल कॉन्फ़िगरेशन नहीं

### 4. MQM स्कोरिंग

KTTC WMT बेंचमार्क में उपयोग किए जाने वाले MQM फ्रेमवर्क को लागू करता है।

**त्रुटि गंभीरता भार:**

- **न्यूट्रल:** 0 अंक (कोई दंड नहीं)
- **माइनर:** 1 अंक (टाइपो, शैली प्राथमिकताएं)
- **मेजर:** 5 अंक (व्याकरण त्रुटियां, गलत अनुवाद)
- **क्रिटिकल:** 10 अंक (लोप, अर्थ परिवर्तन)

**सूत्र:**

```
MQM स्कोर = 100 - (total_penalty / word_count * 1000)
```

**उदाहरण:**

```
पाठ: 50 शब्द
त्रुटियां: 1 माइनर, 2 मेजर
दंड: 1*1 + 2*5 = 11
MQM स्कोर: 100 - (11 / 50 * 1000) = 100 - 220 = 78.0
```

**गुणवत्ता स्तर:**

- **95-100:** उत्कृष्ट (उत्पादन-तैयार)
- **90-94:** अच्छा (छोटे सुधार आवश्यक)
- **80-89:** स्वीकार्य (संशोधन आवश्यक)
- **<80:** खराब (महत्वपूर्ण पुनर्कार्य आवश्यक)

### 5. अनुवाद मेमोरी

**MQM ट्रैकिंग के साथ सिमेंटिक खोज:**

```python
# गुणवत्ता स्कोर के साथ अनुवाद संग्रहीत करें
await tm.add_translation(
    source="API request",
    translation="Запрос API",
    mqm_score=98.5,
    domain="technical"
)

# समान अनुवाद खोजें (sentence-transformers)
results = await tm.search_similar(
    source="API call",
    threshold=0.80  # Cosine similarity
)
# रिटर्न: "Запрос API" (similarity: 0.92, MQM: 98.5)
```

**लाभ:**

- उच्च-गुणवत्ता अनुवादों का पुनः उपयोग
- प्रोजेक्ट्स में स्थिर शब्दावली
- डोमेन-विशिष्ट संगठन

### 6. ऑटो-करेक्शन सिस्टम

**AutoCorrector** पहचानी गई त्रुटियों को प्राकृतिक रूप से ठीक करने के लिए LLM का उपयोग करता है:

**स्तर:**

- **लाइट:** केवल क्रिटिकल और मेजर त्रुटियां ठीक करें
- **फुल:** सभी पहचानी गई त्रुटियां ठीक करें

**प्रक्रिया:**

```
1. एजेंट त्रुटियां पहचानते हैं
2. AutoCorrector सुधार प्रॉम्प्ट जनरेट करता है
3. LLM संदर्भ में सुधार करता है
4. एजेंटों के साथ पुनः मूल्यांकन करें
5. सीमा पूरी होने तक दोहराएं (अधिकतम पुनरावृत्तियां)
```

**परिणाम:**

- मैन्युअल पोस्ट-एडिटिंग से 40% तेज़
- मानव संपादन की तुलना में 60% लागत में कमी
- संदर्भ और प्रकृतिता संरक्षित करता है

### 7. TEaR लूप (Translate-Estimate-Refine)

**IterativeRefinement** TEaR पद्धति को लागू करता है:

```
1. TRANSLATE: प्रारंभिक अनुवाद जनरेट करें (LLM)
2. ESTIMATE: गुणवत्ता का मूल्यांकन करें (Multi-agent QA)
3. REFINE: त्रुटियां ठीक करें और सुधारें (AutoCorrector)
4. अभिसरण या अधिकतम पुनरावृत्तियों तक 2-3 दोहराएं
```

**अभिसरण मानदंड:**

- MQM स्कोर ≥ सीमा (जैसे, 95.0)
- सुधार < न्यूनतम (जैसे, 1.0 अंक)
- अधिकतम पुनरावृत्तियां पूर्ण (जैसे, 3)

## डिज़ाइन निर्णय

### सिंगल LLM के बजाय मल्टी-एजेंट क्यों?

**सिंगल LLM दृष्टिकोण:**

- QA कार्यों में हॅल्युसिनेशन के लिए प्रवण
- भाषा-विशिष्ट त्रुटियां मिस कर सकता है
- असंगत त्रुटि वर्गीकरण

**मल्टी-एजेंट दृष्टिकोण:**

- प्रत्येक एजेंट एक आयाम में विशेषज्ञ
- समानांतर निष्पादन (तेज़)
- हाइब्रिड NLP+LLM हॅल्युसिनेशन कम करता है
- MQM-अनुपालन त्रुटि वर्गीकरण

**शोध समर्थन:** WMT 2025 निष्कर्ष दिखाते हैं कि मल्टी-एजेंट सिस्टम सिंगल-मॉडल QA से सटीकता में 15-20% बेहतर प्रदर्शन करते हैं।

### भाषा-विशिष्ट एजेंट क्यों?

**समस्या:** सामान्य फ्लूएन्सी एजेंट भाषा-विशिष्ट त्रुटियां मिस करते हैं:

- अंग्रेज़ी: आर्टिकल्स (a/an/the), विषय-क्रिया समझौता
- चीनी: माप शब्द (量词), पहलू कण (了/过)
- रूसी: केस समझौता (6 केस), क्रिया पहलू

**समाधान:** NLP लाइब्रेरीज़ के माध्यम से एन्कोडेड मूल-वक्ता ज्ञान वाले विशेष एजेंट।

**सक्रियण:** `target_lang` के आधार पर ऑटो-चयनित:

```python
if target_lang == "en":
    fluency_agent = EnglishFluencyAgent()
elif target_lang == "zh":
    fluency_agent = ChineseFluencyAgent()
elif target_lang == "ru":
    fluency_agent = RussianFluencyAgent()
else:
    fluency_agent = FluencyAgent()  # Generic
```

### हाइब्रिड NLP + LLM क्यों?

**शुद्ध LLM मुद्दे:**

- हॅल्युसिनेशन: ऐसी त्रुटियों का दावा करता है जो मौजूद नहीं हैं
- असंगति: पुनः-रन पर अलग त्रुटियां
- लागत: सरल जाँच के लिए महंगा

**शुद्ध NLP मुद्दे:**

- सीमित सिमेंटिक समझ
- संदर्भीय मुद्दों का पता नहीं लगा सकता
- व्यापक नियम इंजीनियरिंग की आवश्यकता है

**हाइब्रिड लाभ:**

- NLP निर्धारक जाँच प्रदान करता है (कोई हॅल्युसिनेशन नहीं)
- LLM सिमेंटिक समझ प्रदान करता है
- NLP LLM आउटपुट सत्यापित करता है (एंटी-हॅल्युसिनेशन)
- लागत-प्रभावी: सरल जाँच के लिए NLP, जटिल के लिए LLM उपयोग करें

### स्मार्ट रूटिंग क्यों?

**समस्या:** "Hello, world!" के लिए GPT-4.5 का उपयोग व्यर्थ है।

**समाधान:** जटिलता के आधार पर रूट करें:

- सरल पाठ → सस्ते मॉडल (GPT-4o-mini)
- जटिल पाठ → प्रीमियम मॉडल (GPT-4.5, o1-preview)

**प्रभाव:**

- व्यवहार में 60% लागत में कमी
- कोई गुणवत्ता गिरावट नहीं
- स्वचालित, उपयोगकर्ताओं के लिए पारदर्शी

## प्रदर्शन विशेषताएं

### विलंबता

**सिंगल अनुवाद (100 शब्द):**

- NLP विश्लेषण: ~0.1s
- एजेंट मूल्यांकन (5 एजेंट, समानांतर): ~2-5s
- कुल: ~2-6s

**बैच प्रोसेसिंग (1000 अनुवाद):**

- क्रमिक: ~50-100 मिनट
- समानांतर (4 कार्यकर्ता): ~12-25 मिनट
- समानांतर (8 कार्यकर्ता): ~6-12 मिनट

### लागत

**प्रति 1000 शब्द (GPT-4o-mini + स्मार्ट रूटिंग):**

- गुणवत्ता जाँच: $0.01-0.05
- अनुवाद + QA: $0.05-0.15
- ऑटो-करेक्शन के साथ: $0.10-0.25

**मैन्युअल समीक्षा से तुलना:**

- मानव: $100-500 प्रति 1000 शब्द
- KTTC: $0.01-0.25 प्रति 1000 शब्द
- बचत: 90-99%

### सटीकता

**त्रुटि पहचान (WMT बेंचमार्क की तुलना में):**

- प्रिसीजन: 85-92% (कुछ झूठी सकारात्मक)
- रिकॉल: 78-88% (अधिकांश वास्तविक त्रुटियां खोजता है)
- F1 स्कोर: 81-90%

**MQM स्कोर सहसंबंध:**

- मानव MQM की तुलना में: r = 0.82-0.89 (मजबूत सहसंबंध)

## स्केलेबिलिटी

**क्षैतिज स्केलिंग:**

- स्टेटलेस डिज़ाइन (प्रत्येक जाँच स्वतंत्र)
- समानांतर बैच प्रोसेसिंग
- कार्यकर्ताओं के बीच कोई साझा स्थिति नहीं

**लंबवत स्केलिंग:**

- पूरे में Async/await
- समवर्ती LLM API कॉल
- मेमोरी-कुशल (बड़ी फ़ाइलों के लिए स्ट्रीमिंग)

**उत्पादन परिनियोजन:**

```
Load Balancer
    ↓
┌─────────┬─────────┬─────────┐
│ Worker  │ Worker  │ Worker  │
│   1     │   2     │   3     │
└─────────┴─────────┴─────────┘
    ↓         ↓         ↓
┌─────────────────────────────┐
│   Shared Translation Memory │
│   Shared Terminology Base   │
└─────────────────────────────┘
```

## यह भी देखें

- [एजेंट सिस्टम](agent-system.md) - एजेंटों में गहरी गोता
- [MQM फ्रेमवर्क](mqm-scoring.md) - स्कोरिंग विवरण
- [CLI आर्किटेक्चर](../guides/cli-usage.md) - CLI डिज़ाइन
- [API संदर्भ](../reference/api-reference.md) - Python API
